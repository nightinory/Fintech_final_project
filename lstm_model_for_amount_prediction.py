# -*- coding: utf-8 -*-
"""LSTM model for amount prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xIaaRJmoMYwWVErXNps1_itRyfBEyuND
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
from sklearn.preprocessing import MinMaxScaler 
sc = MinMaxScaler(feature_range = (0, 1))
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dropout,BatchNormalization

data = pd.read_csv('total.csv')

"""#Function: AMOUNT

#切割data
"""

data

#切分Test集
test = data.tail(86)
train = data[:len(data)-len(test)]
#只要open high
train_set = train['AMOUNT']
test_set = test['AMOUNT']

"""#歸一化"""

#Normalization
#需將資料做reshape的動作，使其shape為(資料長度,1) 
train_set= train_set.values.reshape(-1,1)
training_set_scaled = sc.fit_transform(train_set)

"""#X_train:將10個日期編號的資料視為一個序列
#Y_train: 預測第i個日期編號的value
"""

X_train = [] 
y_train = []
for i in range(30,len(train_set)):
    X_train.append(training_set_scaled[i-30:i-1, 0]) 
    y_train.append(training_set_scaled[i, 0]) 
X_train, y_train = np.array(X_train), np.array(y_train) 
X_train = np.reshape(X_train, 
                          (X_train.shape[0], X_train.shape[1], 1))

"""#定義網絡層和optimizer function"""

keras.backend.clear_session()
regressor_AMOUNT = Sequential()
regressor_AMOUNT.add(LSTM(units = 200, return_sequences = True,input_shape = (X_train.shape[1], 1)))
regressor_AMOUNT.add(Dropout(0.2))
regressor_AMOUNT.add(LSTM(units = 200,return_sequences = True))
regressor_AMOUNT.add(Dropout(0.2))
regressor_AMOUNT.add(LSTM(units = 200))
regressor_AMOUNT.add(Dropout(0.2))
regressor_AMOUNT.add(Dense(units = 1))
regressor_AMOUNT.compile(optimizer = 'adam', loss = 'mean_squared_error')

"""#訓練Train data(可設定epoch和batch size)"""

history = regressor_AMOUNT.fit(X_train, y_train, epochs = 100, batch_size = 32)
plt.title('train_loss')
plt.ylabel('loss')
plt.xlabel('Epoch')
plt.plot( history.history["loss"])

"""#用Test data evaluate模型"""

dataset_total = pd.concat((train['AMOUNT'], test['AMOUNT']), axis = 0)
inputs = dataset_total[len(dataset_total) - len(test) - 30:].values
inputs = inputs.reshape(-1,1)
inputs = sc.transform(inputs)
X_test = []
for i in range(30, len(inputs)):
    X_test.append(inputs[i-30:i-1,0])
X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

predicted_AMOUNT = regressor_AMOUNT.predict(X_test)
predicted_AMOUNT = sc.inverse_transform(predicted_AMOUNT)

"""#Plotting

#Testset evalutaion(plot)
"""

plt.plot(test['AMOUNT'].values, color = 'black', label = 'Real AMOUNT')
plt.plot(predicted_AMOUNT, color = 'green', label = 'Predicted AMOUNT')
plt.title('TATA AMOUNT Prediction')
plt.xlabel('DATE_RANK')
plt.ylabel('AMOUNT')
plt.legend()
plt.show()
# plt.savefig('lstm_2330.png')

"""#Model optimizing"""

units = [65,70,75,80,85]
dropout = [0,0.2,0.4,0.6]
batchsize = [16,32,64,256,512]
epochs = [100,150,200,250,300]
for un in units:
  for do in dropout:
    for bs in batchsize:
      for ep in epochs:
        print('units =',un,'dropout =',do,'batchsize = ',bs,'epochs =',ep)
        keras.backend.clear_session()
        regressor_AMOUNT = Sequential()
        regressor_AMOUNT.add(LSTM(units = un, return_sequences = True,input_shape = (X_train.shape[1], 1)))
        regressor_AMOUNT.add(Dropout(do))
        regressor_AMOUNT.add(LSTM(units = un))
        regressor_AMOUNT.add(Dropout(do))
        regressor_AMOUNT.add(Dense(units = 1))
        regressor_AMOUNT.compile(optimizer = 'adam', loss = 'mean_squared_error')

        history = regressor_AMOUNT.fit(X_train, y_train, epochs = ep, batch_size = bs)
        plt.title('train_loss')
        plt.ylabel('loss')
        plt.xlabel('Epoch')
        plt.plot( history.history["loss"])
        plt.legend()
        plt.show()
        
        predicted_AMOUNT = regressor_AMOUNT.predict(X_test)
        predicted_AMOUNT = sc.inverse_transform(predicted_AMOUNT)
        plt.plot(test['AMOUNT'].values, color = 'black', label = 'Real AMOUNT')
        plt.plot(predicted_AMOUNT, color = 'green', label = 'Predicted AMOUNT')
        plt.title('TATA AMOUNT Prediction')
        plt.xlabel('DATE_RANK')
        plt.ylabel('AMOUNT')
        plt.legend()
        plt.show()

"""#Found best parameter"""

units = [75]
dropout = [0.2]
batchsize = [256]
epochs = [250]
for un in units:
  for do in dropout:
    for bs in batchsize:
      for ep in epochs:
        print('units =',un,'dropout =',do,'batchsize = ',bs,'epochs =',ep)
        keras.backend.clear_session()
        regressor_AMOUNT = Sequential()
        regressor_AMOUNT.add(LSTM(units = un, return_sequences = True,input_shape = (X_train.shape[1], 1)))
        regressor_AMOUNT.add(Dropout(do))
        regressor_AMOUNT.add(LSTM(units = un))
        regressor_AMOUNT.add(Dropout(do))
        regressor_AMOUNT.add(Dense(units = 1))
        regressor_AMOUNT.compile(optimizer = 'adam', loss = 'mean_squared_error')

        history = regressor_AMOUNT.fit(X_train, y_train, epochs = ep, batch_size = bs)
        plt.title('train_loss')
        plt.ylabel('loss')
        plt.xlabel('Epoch')
        plt.plot( history.history["loss"])
        plt.legend()
        plt.show()
        
        predicted_AMOUNT = regressor_AMOUNT.predict(X_test)
        predicted_AMOUNT = sc.inverse_transform(predicted_AMOUNT)
        plt.plot(test['AMOUNT'].values, color = 'black', label = 'Real AMOUNT')
        plt.plot(predicted_AMOUNT, color = 'green', label = 'Predicted AMOUNT')
        plt.title('TATA AMOUNT Prediction')
        plt.xlabel('DATE_RANK')
        plt.ylabel('AMOUNT')
        plt.legend()
        plt.show()
        '''
        plt.title('train_loss')
        plt.ylabel('loss')
        plt.xlabel('Epoch')
        plt.plot( history.history["loss"])
        '''

"""#True value and Predicted value 的差平均 ==>作為預測結果的校正值"""

import statistics
adjust_value =[]
for i in range(predicted_AMOUNT.shape[0]):
  adjust_value.append(abs(test['AMOUNT'].values[i]-int(predicted_AMOUNT[i].flatten())))
Prediction_adjustment = statistics.mean(adjust_value)

Prediction_adjustment

"""#Predict a new data"""

#Want to get the longest open account period, and gets 1967 for the earliest account
cust_info = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Fintech/cust_info_nobreach.csv')
print(cust_info.loc[:,"open_acct_year"].min())

#Enter the investor's new Transaction record(amount)
Data_to_predict = {'Cust_NO':input('Enter Cust_NO rank:'),
                    'DATE_RANK':input('Enter date rank:'),
                    'AMOUNT':input('AMOUNT:'),
                                }

#Find the investor's OPEN_ACCT_YEAR and AGE_LEVEL for alert_range assessment
Cust_NO = (Data_to_predict['Cust_NO'])
Cust_info = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Fintech/cust_info_nobreach.csv')
Cust_info = Cust_info[Cust_info["cust"] == Cust_NO]
AGE_LEVEL = Cust_info[["age_level"]].values
AGE_LEVEL_weight = 1-(int(np.asarray(AGE_LEVEL))/6) #All six level
OPEN_ACCT_YEAR = Cust_info[["open_acct_year"]].values.flatten()
OPEN_ACCT_YEAR_weight = 1-((2022-int(np.asarray(OPEN_ACCT_YEAR)))/(2022-1967))# The longest period of an account

#Data_to_predict = pd.Series(Data_to_predict['AMOUNT'])
#dataset_total = pd.concat((data['AMOUNT'],Data_to_predict),axis = 0)
dataset_total = data['AMOUNT']
inputs = dataset_total[len(dataset_total)- 29:].values
inputs = inputs.reshape(-1,1)
inputs = sc.transform(inputs)
X_test = np.array(inputs)
X_test = np.reshape(X_test, (1,X_test.shape[0], -1))
predicted_AMOUNT = regressor_AMOUNT.predict(X_test)
predicted_AMOUNT = sc.inverse_transform(predicted_AMOUNT)
predicted_AMOUNT = predicted_AMOUNT.flatten()
predicted_AMOUNT = int(np.asarray(predicted_AMOUNT))

Predicted_drop =abs(int(Data_to_predict['AMOUNT'])-predicted_AMOUNT)
if Predicted_drop>=Prediction_adjustment:
  Alert_range = abs(Predicted_drop-Prediction_adjustment)
else:
  Alert_range = 0
  Alert_range = Alert_range*AGE_LEVEL_weight*OPEN_ACCT_YEAR_weight

if Alert_range >= predicted_AMOUNT*0.1:
  print('Alert')
else:
  print('Good luck!!')